{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWcODvJIhW6PBlHAr4F6oE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raja-khalil/Python-training/blob/main/Rede_Neural_do_Zero_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1WbbzX93NvZO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor() # definindo a conversão de imagem para tensor\n",
        "\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # Carrega a parte de treino do dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # Carrega a parte de validação do dataset\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes\n",
        "\n"
      ],
      "metadata": {
        "id": "oeRhCLz1Psoi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "imagens, etiquetas = next(dataiter)\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap=\"gray_r\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "twviXAsXRH3v",
        "outputId": "c57a6809-f982-49cd-c920-299f456b8800"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b2f57895c90>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape)#para verificar a as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape)#para verificar as dimensões do tensor de cada etiqueta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0LUS1R_SebW",
        "outputId": "f6fbf605-e585-4bd6-c66f-905d057712a4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Modelo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 128) # camada de entrada, 784 neurônios que se ligam a 128\n",
        "        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neurônios que se ligam a 64\n",
        "        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neurônios que se ligam a 10\n",
        "        # para a camada de saida não é necessário definir nada pois só precisamos pegar o output da camada interna 2\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1\n",
        "        X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para a camada interna 2\n",
        "        X = self.linear3(X) # função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
        "        return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda\n"
      ],
      "metadata": {
        "id": "HI2m7nWsS0S-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "\n",
        "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a política de atualização dos pesos e da bias\n",
        "    inicio = time() # timer para sabermos quanto tempo levou o treino\n",
        "\n",
        "    criterio = nn.NLLLoss() # definindo o criterio para calcular a perda\n",
        "    EPOCHS = 10 # numero de epochs que o algoritmo rodará\n",
        "    modelo.train() # ativando o modo de treinamento do modelo\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        perda_acumulada = 0 # inicialização da perda acumulada da epoch em questão\n",
        "\n",
        "        for imagens, etiquetas in trainloader:\n",
        "\n",
        "            imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens para \"vetores\" de 28*28 casas para ficarem compatíveis com a entrada da rede\n",
        "            otimizador.zero_grad() # zerando os gradientes por conta do ciclo anterior\n",
        "\n",
        "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
        "            perda_instantaea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
        "\n",
        "            perda_instantaea.backward() # back propagation a partir da perda\n",
        "\n",
        "            otimizador.step() # Atualizando os pesos e a bias\n",
        "\n",
        "            perda_acumulada += perda_instantaea.item() # atualização de perda acumulada\n",
        "\n",
        "        else:\n",
        "          print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "    print(\"\\nTempo de treino (em minutos) =\", (time()-inicio)/60)"
      ],
      "metadata": {
        "id": "Gqkp-VQ9Ttfr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "    conta_corretas, conta_todas = 0, 0\n",
        "    for imagens, etiquetas in valloader:\n",
        "        for i in range(len(etiquetas)):\n",
        "            img = imagens[i].view(1, 784)\n",
        "            # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
        "            with torch.no_grad():\n",
        "                logps = modelo(img.to(device)) # output do modelo em escala logarítmica\n",
        "\n",
        "            ps = torch.exp(logps) # converte output para escala normal (lembrando que é um tensor)\n",
        "            probab = list(ps.cpu().numpy()[0])\n",
        "            etiqueta_pred = probab.index(max(probab)) # converte o tensor em um número, no caso, o número que o modelo previu\n",
        "            etiqueta_certa = etiquetas.numpy()[i]\n",
        "            if etiqueta_certa == etiqueta_pred: # compara a previsão com o valor correto\n",
        "                conta_corretas += 1\n",
        "            conta_todas += 1\n",
        "\n",
        "    print(\"Total de imagens testadas =\", conta_todas)\n",
        "    print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todas))\n"
      ],
      "metadata": {
        "id": "09ykPt1eUzcF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo() # inicializa o modelo\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # modelo rodará na GPU se possível\n",
        "modelo.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biL-f8LbWaGT",
        "outputId": "09426f04-31d5-438e-e26f-ed1aee6ae669"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ru3PIK6xXxFz"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}